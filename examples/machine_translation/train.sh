unilm_train \
    --base_model xlm-roberta \
    --model_name_or_path xlm-roberta-large \
    --model_recover_path xlm-roberta-large-en-de/pytorch_model.bin \
    --batch_size 24 \
    --src_file news-commentary-v9.de-en/news-commentary-v9.de-en.en \
    --tgt_file news-commentary-v9.de-en/news-commentary-v9.de-en.de \
    --max_src_len 64 \
    --max_tgt_len 64 \
    --mask_prob 0.7 \
    --seed 42 \
    --fp16 \
    --output_dir output_dir/news-commentary-v9.de-en \
    --gradient_accumulation_steps 4 \
    --lr 3e-5 \
    --num_train_epochs 30
